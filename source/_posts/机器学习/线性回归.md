---
title: 线性/多项式/岭回归
katex: true
categories:
  - 机器学习
  - 监督学习
  - 回归问题
tags:
  - 线性回归
  - 非线性回归
  - 岭回归
  - Python
cover: 'https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200509152200.png'
abbrlink: 5297fabb
date: 2020-05-08 13:11:22
---

# 线性回归
## 引言
线性回归 (Linear）是利用数理统计中回归分析，**来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。**
>线性回归利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模，使用形如 y=w T x+b的线性模型函数拟合数据输入和输出之间的映射关系。
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508132209.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">线性回归</div>
</center>
>这种函数是一个或多个称为回归系数的模型参数的线性组合，只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。

## 实际用途
线性回归在机器学习中主要有两方面的用途
- 如果目标是预测或者映射，线性回归可以用来对观测数据集的 y 和 X的值拟合出一个预测模型。当完成这样一个模型以后，对于一个新增的 X 值，在没有给定与它相配对的 y 的情况下，可以用这个拟合过的模型预测出一个y 值 。
- 给定一个变量 y 和一些变量 X1,⋯,X<sub>p</sub> 这些 变量有可能与 y 相关，线性回归分析可以用来量化 y 与 X<sub>j</sub> 之间相关性的强度，评估出与 y 不相关的 X<sub>j</sub> 并识别出哪些 X<sub>j</sub> 的子集包含了关于 y 的冗余信息。

## 应用实例
### 背景
与房价密切相关的除了单位的房价，还有房屋的尺寸。我们可以根据已知的房屋成交价和房屋的尺寸进行线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行成交价格的预测。
### 目标
对房屋成交信息建立回归方程，并依据回归方程对房屋价格进行预测
### 技术路线
sklearn. linear_model.LinearRegression
```
fit_intercept : 布尔型参数，表示是否计算该模型截距。可选参数。
n ormalize : 布尔型参数，若为 True ，则 X 在回归前进行归一化。可选参数。默认值为 False 。
copy_X : 布尔 型参数 若 为 True ，则 X 将被复制；否则将被覆盖。 可选参数。默认值 为 True 。
n_jobs : 整型参数，表示用于计算的作业数量；若为 1 ，则用所有的 CPU 。可选参数。默认值为 1 。
```
### 实例数据
为了方便展示，成交信息只使用了房屋的面积以及对应的成交价格。
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508133709.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">成交信息</div>
</center>

### 可行性分析
散点图二维数据可视化，观察房屋成交价格和房屋尺寸间是否存在线性关系。
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508135902.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">数据散点图</div>
</center>

### 实验过程
建立工程并导入 sklearn 包，加载训练数据，建立回归方程，最后可视化处理。
#### 代码演示
```python
import matplotlib.pyplot as plt 		# 导入matplotlib的pyplot子库
import numpy as np 						# 导入linear_model 模块进行线性回归
from sklearn import linear_model
 
# 读取数据集
datasets_X = []							# 存储房屋尺寸和房屋成交价格数据
datasets_Y = []							# 打开数据集所在文件prices.txt
fr = open('prices.txt','r')
lines = fr.readlines()					# 一次读取整个文件
for line in lines:						# 逐行进行操作，循环遍历所有数据
    items = line.strip().split(',') 	# 去除数据文件中的逗号
    datasets_X.append(int(items[0])) 	# 将读取的数据转换为int并写入列表
    datasets_Y.append(int(items[1]))
 
length = len(datasets_X)
datasets_X = np.array(datasets_X).reshape([length,1]) # 将数据转化为数组，并变为二维，以符合线性回归拟合函数输入参数要求。
datasets_Y = np.array(datasets_Y)		
 
minX = min(datasets_X)
maxX = max(datasets_X)
X = np.arange(minX,maxX).reshape([-1,1])# 以数据datasets_X 的最大值和最小值为范围，建立等差数列，方便后续画图
 
linear = linear_model.LinearRegression()# 调用线性回归模块，建立回归方程，拟合数据
linear.fit(datasets_X, datasets_Y)		# 函数用于拟合输入输出数据，调用形式为 linear.fit (X,y,sample_weight = None)

print('Coefficients:', linear.coef_)	# 查看回归方程系数
print('intercept:', linear.intercept_)	# 查看回归方程截距
# 图像中显示
plt.scatter(datasets_X, datasets_Y, color = 'red') # scatter函数用于绘制数据点，这里表示用红色绘制数据点；
plt.plot(X, linear.predict(X), color = 'blue') # plot函数用来绘制直线，这里表示用蓝色绘制回归线；
plt.xlabel('Area')						# xlabel和ylabel用来指定横纵坐标的名称。
plt.ylabel('Price')
plt.show()
```

#### 结果展示
通过回归方程拟合的直线与原有数据点的关系如右图所示，依据该回归方程 即可通过房屋的尺寸，来预测房屋的成交价格。
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508142234.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">拟合结果</div>
</center>

----------
# 多项式回归
## 引言
多项式回归 (Polynomial Regression)是**研究一个因变量与一个或多个自变量间多项式的回归分析方法。**如果自变量只有一个时，称为一元多项式回归；如果自变量有多个时，称为多元多项式回归 。

一元 m 次多项式回归方程为：
>![](https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508170235.png)

二元二次多项式回归方程为：
>![](https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508170348.png)

> 在一元回归分析中，如果依变量 y 与自变量 x 的关系为非线性的，但是又找不到适当的函数曲线来拟合，则可以采用一元多项式回归。
> 
> 多项式回归的最大优点就是可以通过增加 x 的高次项对实测点进行逼近，直至满意为止。
> 
> 事实上，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，因为任一函数都可以分段用多项式来逼近。

在线性回归实例中，是运用直线来拟合数据输入与输出之间的线性关系。不同于线性回归，多项式回归是**使用曲线拟合数据的输入与输出的映射关系。**
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508171227.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">一元多项式回归</div>
</center>

## 应用实例
### 背景
我们在前面已经根据已知的房屋成交价和房屋的尺寸进行了线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行了成交价格的预测，但是在实际的应用中这样的拟合往往不够好，因此我们在此对该数据集进行多项式回归。
### 目标
对房屋成交信息建立多项式回归方程，并依据回归方程对房屋价格进行预测
### 技术路线
sklearn.preprocessing.PolynomialFeatures
### 代码演示
代码部分大部分和线性回归一样，这里给出不同的地方
```python
import matplotlib.pyplot as plt
import numpy as np
from sklearn import linear_model				# 导入线性模型和多项式特征构造模块
from sklearn.preprocessing import PolynomialFeatures
...
poly_reg = PolynomialFeatures(degree = 2)		# degree=2表示建立 datasets_X的二次多项式特征X_poly
X_poly = poly_reg.fit_transform(datasets_X)
lin_reg_2 = linear_model.LinearRegression()		# 创建线性回归，使用线性模型学习X_poly和datasets_Y之间的映射关系
lin_reg_2.fit(X_poly, datasets_Y)
...
```

### 结果展示
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508173406.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">拟合结果</div>
</center>
------

# 多项式回归
## 引言
### 线性回归的局限
>对于一般地线性回归问题，参数的求解采用的是最小二乘法，其目标函数如下：
>$$argmin\vert\vert Xw-y\vert\vert^2$$
>参数w的求解，也可以使用如下矩阵方法进行：
>$$w={(X^TX)}^{-1}X^Ty$$
>对于矩阵X，若某些列线性相关性较大（即训练样本中某些属性线性相关），就会导致$X^TX$的值接近 0 ，在计算$(X^TX)^{-1}$时就会出现不稳定性：
**结论：传统的基于最小二乘的线性回归法缺乏稳定性。**

### 岭回归
岭回归的优化目标：
>$$argmin\vert\vert Xw-y\vert\vert^2+a\vert\vert w\vert\vert^2$$
>对应的矩阵求解方法为：
>$$w={(X^TX+\alpha I)}^{-1}X^Ty$$
>
>**岭回归 (ridge regression) 是一种专用于共线性数据分析的有偏估计回归方法，是一种改良的最小二乘估计法，对某些数据的拟合要强于最小二乘法。**

## 应用实例
### 数据介绍
数据为某路口的交通流量监测数据，记录全年小时级别的车流量。
### 实验目的
根据已有的数据创建多项式特征，使用岭回归模型代替一般的线性模型，对
车流量的信息进行多项式回归。
### 技术路线
sklearn.linear_model.Ridgefrom、
sklearn.preprocessing.PolynomialFeatures
```plain
alpha ：正则化因子，对应于损失函数中的 𝜶
fit_intercept ：表示是否计算截距
solver ：设置计算参数的方法，可选参数 auto ’、 svd ’、 sag ’等
```

### 数据实例
```plain
HR：一天中的第几个小时 0 23
WEEK_DAY：一周中的第几天 0 6
DAY_OF_YEAR：一年中的第几天 1 365
WEEK_OF_YEAR：一年中的第几周 1 53
TRAFFIC_COUNT：交通流量
```
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508193752.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">数据实例</div>
</center>
```python
import numpy as np
from sklearn.linear_model import Ridge	# 通过 sklearn.linermodel 加载岭回归方法
from sklearn import cross_validation	# 加载交叉验证模块，加载 matplotilib 模块
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures # 通过..加载...用于创建多项式特征，如 ab 、 a2 、 b2
data= np.genfromtxt('data.txt')		# 使用 numpy 的方法从 txt 文件中加载数据
plt.plot(data[:,4])					# 使用 plt 展示车流量信息
X=data[:,:4]						# X用于保存 0 3 维数据，即属性
y=data[:,4]							# y用于保存第 4 维数据，即车流量
poly= PolynomialFeatures(6)			# 用于创建最高次数 6 次方的的多项式特征，多次试验后决定采用 6 次
X= poly.fit_transform(X)			# X为创建的多项式特征
train_set_X , test_set_X , train_set_y , test_set_y =cross_validation.train_test_split(X,y,test_size = 0.3,random_state =0)				# 将所有数据划分为训练集和测试集，test_size 表示测试集的比例
clf=Ridge(alpha=1.0,fit_intercept = True)# 接下来我们创建岭回归实例
clf.fit(train_set_X,train_set_y)	# 调用 fit 函数使用 训练集训练回归器
clf.score(test_set_X,test_set_Y	)	# 利用测试集计算回归曲线的拟合优度， clf.score 返回值为 0.7375
#拟合优度，用于评价拟合好坏，最大为 1 ，无最小值，当对所有输入都输出同一个值时，拟合优度为 0 。
start=200 							# 接下来我们画一段 200 到 300 范围内的拟合 曲线
end=300
y_pre clf.predict(X) 				# 是调用 predict 函数的拟合值
time= np.arange(start,end)
plt.plot(time,y[start:end],'b', label ="real")
plt.plot(time,y_pre[start:end],'r', label ='predict') # 展示真实数据（蓝色）以及拟合的曲线（红色）
plt.legend(loc =‘upper left’) # 设置图例的位置
plt.show()
```

### 结果
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508200329.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">车流量信息</div>
</center>
分析结论：预测值和实际值的走势大致相同
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);display:inline;margin:0" 
    src="https://cdn.jsdelivr.net/gh/DSzhongweizi/Resources/article/20200508200428.png" width=300 />
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;">结论</div>
</center>
